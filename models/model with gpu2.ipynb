{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with mobilenet\n",
    "\n",
    "- New environment for tf 1.15\n",
    "- Pip/Conda install numpy, matplotlib, pandas, jupyterlab, keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "#tf.keras.backend.clear_session()  # For easy reset of notebook state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simply load reshaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"C:/Users/Alicia/Desktop/new train data\")\n",
    "\n",
    "train_converted = np.load('train_data_converted2.npy', allow_pickle=True)\n",
    "test_converted = np.load('test_data_converted2.npy', allow_pickle=True)\n",
    "train_label_converted = np.load('train_label_converted2.npy', allow_pickle=True)\n",
    "test_label_converted = np.load('test_label_converted2.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6737, 224, 224, 3)\n",
      "(1684, 224, 224, 3)\n",
      "(6737, 1)\n",
      "(1684, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_converted.shape)\n",
    "print(test_converted.shape)\n",
    "print(train_label_converted.shape)\n",
    "print(test_label_converted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet()\n",
    "# copy of pretrained MobileNet pretrained model with saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 4,253,864\n",
      "Trainable params: 4,231,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1, 4)           4100      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 7,556\n",
      "Non-trainable params: 3,225,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MobileNet(include_top=False, input_shape=(224,224,3))\n",
    "#for layer in model.layers:\n",
    " #   layer.trainable = False\n",
    "    \n",
    "# or if we want to set the first 20 layers of the network to be non-trainable\n",
    "for layer in model.layers[11:]: #[11:81]: freeze layers of 13 \n",
    "    layer.trainable=False \n",
    "for layer in model.layers[:11]: #and model.layers[81:]: freeze layers of 13\n",
    "    layer.trainable=True \n",
    "\n",
    "#flat1 = Flatten()(model.outputs)\n",
    "#class1 = Dense(1024, activation='relu')(flat1)\n",
    "x = GlobalAveragePooling2D()(model.output)\n",
    "class1 = Reshape((1,1,1024))(x) # None,1,1,4\n",
    "class2 = Dropout(0.25)(class1) # original 0.001, instead of 0.20, try 0.25 \n",
    "class3 = Conv2D(filters=4, kernel_size=(1,1), padding='same', data_format='channels_last')(class2) # original 1,1 instead of 3,3, softmax instead of relu\n",
    "\n",
    "#class4 = Reshape((-1,4))(class3) # None,1,4\n",
    "\n",
    "#new_dim = tuple([x for x in class3.shape.as_list() if x != 1 and x is not None])\n",
    "#class4 = Reshape(new_dim)(class3) # (4,)\n",
    "\n",
    "class4 = Reshape((4,))(class3)\n",
    "class5 = Activation('softmax')(class4)\n",
    "\n",
    "#class1 = Dense(1024, activation='relu')(x)\n",
    "#class2 = Dropout(0.25)(class1)\n",
    "#class3 = Dense(512, activation='relu')(class2)\n",
    "#class4 = Dropout(0.5)(class3)\n",
    "\n",
    "#output = Dense(4, activation='softmax')(class4)\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=class5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000192E58A7288> True\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x0000019793EADA88> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E5234E88> True\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E58BC188> True\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E58AF288> True\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E584ECC8> True\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E5274888> True\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E527A888> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E52939C8> True\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E52B47C8> True\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E52BD848> True\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x00000192E52DC208> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E52F2E88> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E52FEE88> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E53057C8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E5328C48> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E5342C88> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E534CC88> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E5364708> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E538B588> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5394EC8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E53AE788> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E53D2848> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E53DBA88> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x00000192E53FFE88> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E5415CC8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E5423D08> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E542A608> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E5440E08> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E5465B08> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5471AC8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E5492108> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E54B0308> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E54BAF08> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E54DA148> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E54FAB08> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5501EC8> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x00000192E5525CC8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E553CB08> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E5549908> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5546AC8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E5564A48> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E558A848> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5595908> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E51E3AC8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E55B3C48> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E55CCE88> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E55E2708> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E560F448> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5608D48> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E5632F08> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E5651188> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E565EBC8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E5680208> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E569D908> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E56A4FC8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E56BDE08> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E56E2C48> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E56F2788> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E5712C48> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E572CDC8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5736D48> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000192E57507C8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000192E5775E08> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000192E5780FC8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000192E5798948> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001979347E888> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000019793488908> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000197934AB2C8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000197934C8248> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000197934D2E48> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000197934F6108> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000197935116C8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000019793519248> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001979353DD88> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x0000019793554CC8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x0000019793560C48> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000019793568588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001979357DD88> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000197935A3BC8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000197935ADB88> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x00000197935CED48> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x00000197935F3208> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x00000197935FCDC8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001979361E088> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001979363F148> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x0000019793645E88> False\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x00000192E58A7788> True\n",
      "<keras.layers.core.Reshape object at 0x0000019793691EC8> True\n",
      "<keras.layers.core.Dropout object at 0x0000019793695088> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000197936950C8> True\n",
      "<keras.layers.core.Reshape object at 0x0000019793695148> True\n",
      "<keras.layers.core.Activation object at 0x0000019797342988> True\n"
     ]
    }
   ],
   "source": [
    "# Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.15.0 \n",
      "Keras version: 2.2.4 \n",
      "CUDA version: 10.0 \n",
      "cuDNN version: 7\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.platform import build_info\n",
    "print('Tensorflow version: {} \\nKeras version: {} \\nCUDA version: {} \\ncuDNN version: {}'.format(tensorflow.__version__,\n",
    "                                                                                                 keras.__version__,\n",
    "                                                                                                 build_info.cuda_version_number,\n",
    "                                                                                                 build_info.cudnn_version_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we shall check if Tensorflow has detected the GPU on your system. Running the next block should return an entry with `device_type: \"GPU\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14943540473770986819, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10051747840\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3624114045640516144\n",
       " physical_device_desc: \"device: 0, name: TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, we shall check if Tensorflow can <i> access </i> the GPU found in the previous block. Running the next block should return `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we shall verify if Keras (the high-level API running Tensorflow as the backend) will be running with the GPU (where possible). The output should read something like `['/job:localhost/replica:0/task:0/device:GPU:0']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam \n",
    "opt = Adam(lr=0.0001)\n",
    "\n",
    "# keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 6737 samples, validate on 1684 samples\n",
      "Epoch 1/20\n",
      "6737/6737 [==============================] - 45s 7ms/step - loss: 1.1638 - acc: 0.5456 - val_loss: 1.0168 - val_acc: 0.6152\n",
      "Epoch 2/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.6314 - acc: 0.7635 - val_loss: 0.7314 - val_acc: 0.7447\n",
      "Epoch 3/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.4313 - acc: 0.8507 - val_loss: 0.6222 - val_acc: 0.7922\n",
      "Epoch 4/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.3393 - acc: 0.8850 - val_loss: 0.5629 - val_acc: 0.8201\n",
      "Epoch 5/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.2870 - acc: 0.9071 - val_loss: 0.4821 - val_acc: 0.8610\n",
      "Epoch 6/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.2598 - acc: 0.9147 - val_loss: 0.4651 - val_acc: 0.8812\n",
      "Epoch 7/20\n",
      "6737/6737 [==============================] - 40s 6ms/step - loss: 0.2276 - acc: 0.9239 - val_loss: 0.4321 - val_acc: 0.8842\n",
      "Epoch 8/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.2152 - acc: 0.9325 - val_loss: 0.5009 - val_acc: 0.8783\n",
      "Epoch 9/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1975 - acc: 0.9365 - val_loss: 0.3883 - val_acc: 0.9020\n",
      "Epoch 10/20\n",
      "6737/6737 [==============================] - 40s 6ms/step - loss: 0.1804 - acc: 0.9411 - val_loss: 0.3744 - val_acc: 0.9020\n",
      "Epoch 11/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1704 - acc: 0.9427 - val_loss: 0.3674 - val_acc: 0.9032\n",
      "Epoch 12/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1603 - acc: 0.9492 - val_loss: 0.3769 - val_acc: 0.9002\n",
      "Epoch 13/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1505 - acc: 0.9513 - val_loss: 0.3601 - val_acc: 0.9163\n",
      "Epoch 14/20\n",
      "6737/6737 [==============================] - 40s 6ms/step - loss: 0.1453 - acc: 0.9535 - val_loss: 0.3526 - val_acc: 0.9145\n",
      "Epoch 15/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1419 - acc: 0.9521 - val_loss: 0.3313 - val_acc: 0.9175\n",
      "Epoch 16/20\n",
      "6737/6737 [==============================] - 40s 6ms/step - loss: 0.1302 - acc: 0.9608 - val_loss: 0.3285 - val_acc: 0.9204\n",
      "Epoch 17/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1213 - acc: 0.9604 - val_loss: 0.3140 - val_acc: 0.9210\n",
      "Epoch 18/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1239 - acc: 0.9607 - val_loss: 0.3311 - val_acc: 0.9228\n",
      "Epoch 19/20\n",
      "6737/6737 [==============================] - 40s 6ms/step - loss: 0.1149 - acc: 0.9635 - val_loss: 0.3156 - val_acc: 0.9293\n",
      "Epoch 20/20\n",
      "6737/6737 [==============================] - 39s 6ms/step - loss: 0.1142 - acc: 0.9639 - val_loss: 0.3014 - val_acc: 0.9305\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(train_converted, train_label_converted, epochs=20, validation_data= (test_converted, test_label_converted), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1, 4)           4100      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 7,556\n",
      "Non-trainable params: 3,225,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(training.history['acc'])\n",
    "plt.plot(training.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684/1684 [==============================] - 4s 3ms/step\n",
      "Tested Acc: 0.9305225651790864\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_converted, test_label_converted)\n",
    "\n",
    "print(\"Tested Acc:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63417435 0.04833587 0.06494177 0.25254798] 0\n",
      "[0.8295751  0.08056274 0.04428603 0.0455761 ] 0\n",
      "[0.4945213  0.08632442 0.15080382 0.2683505 ] 0\n",
      "[0.7791041  0.16179712 0.00856867 0.05053012] 0\n",
      "[0.0374164  0.87216645 0.00547148 0.08494562] 1\n",
      "[0.11929215 0.74862653 0.01534309 0.11673824] 1\n",
      "[0.01300532 0.9799398  0.0019626  0.00509229] 1\n",
      "[0.02279518 0.20453303 0.7181984  0.0544734 ] 2\n",
      "[0.04270183 0.23348512 0.60674036 0.11707267] 2\n",
      "[0.00218068 0.07137399 0.90116036 0.02528502] 2\n"
     ]
    }
   ],
   "source": [
    "#print(train_label[1228]) # 0 to 268, 269 to 619, 620 to 1227, 1228 to 2405\n",
    "#print(train_label.shape) # 2406\n",
    "\n",
    "#print(test_label[308]) # 0 to 67, 68 to 155, 156 to 307, 308 to 602\n",
    "#print(test_label.shape) # 603\n",
    "\n",
    "print(predictions[0], np.argmax(predictions[0]))\n",
    "\n",
    "print(predictions[44], np.argmax(predictions[44]))\n",
    "\n",
    "print(predictions[80], np.argmax(predictions[80]))\n",
    "\n",
    "print(predictions[122], np.argmax(predictions[122]))\n",
    "\n",
    "print(predictions[200], np.argmax(predictions[200]))\n",
    "\n",
    "print(predictions[250], np.argmax(predictions[250]))\n",
    "\n",
    "print(predictions[300], np.argmax(predictions[300]))\n",
    "\n",
    "print(predictions[500], np.argmax(predictions[500]))\n",
    "\n",
    "print(predictions[503], np.argmax(predictions[503]))\n",
    "\n",
    "print(predictions[602], np.argmax(predictions[602]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = []\n",
    "\n",
    "for i in range(1684):\n",
    "    prediction_labels.append(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(test_label, predicted_label):\n",
    "    cm = np.zeros(shape=(4,4))\n",
    "    \n",
    "    for i in range(1684):\n",
    "        cm[int(test_label[i]), int(predicted_label[i])] += 1\n",
    "        \n",
    "    cm[0,:] = cm[0,:]/sum(cm[0,:])\n",
    "    cm[1,:] = cm[1,:]/sum(cm[1,:])\n",
    "    cm[2,:] = cm[2,:]/sum(cm[2,:])\n",
    "    cm[3,:] = cm[3,:]/sum(cm[3,:])\n",
    "    \n",
    "    return cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88198758 0.04347826 0.         0.07453416]\n",
      " [0.03719008 0.94628099 0.         0.01652893]\n",
      " [0.02457002 0.10565111 0.83292383 0.03685504]\n",
      " [0.00457666 0.01029748 0.00457666 0.9805492 ]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_label_converted, prediction_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_mobilenet_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('trained_mobilenet_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1, 4)           4100      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 7,556\n",
      "Non-trainable params: 3,225,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(test_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63417435 0.04833587 0.06494177 0.25254798] 0\n",
      "[0.8295751  0.08056274 0.04428603 0.0455761 ] 0\n",
      "[0.4945213  0.08632442 0.15080382 0.2683505 ] 0\n",
      "[0.7791041  0.16179712 0.00856867 0.05053012] 0\n",
      "[0.0374164  0.87216645 0.00547148 0.08494562] 1\n",
      "[0.11929215 0.74862653 0.01534309 0.11673824] 1\n",
      "[0.01300532 0.9799398  0.0019626  0.00509229] 1\n",
      "[0.02279518 0.20453303 0.7181984  0.0544734 ] 2\n",
      "[0.04270183 0.23348512 0.60674036 0.11707267] 2\n",
      "[0.00218068 0.07137399 0.90116036 0.02528502] 2\n"
     ]
    }
   ],
   "source": [
    "#print(train_label[1228]) # 0 to 268, 269 to 619, 620 to 1227, 1228 to 2405\n",
    "#print(train_label.shape) # 2406\n",
    "\n",
    "#print(test_label[308]) # 0 to 67, 68 to 155, 156 to 307, 308 to 602\n",
    "#print(test_label.shape) # 603\n",
    "\n",
    "print(predictions[0], np.argmax(predictions[0]))\n",
    "\n",
    "print(predictions[44], np.argmax(predictions[44]))\n",
    "\n",
    "print(predictions[80], np.argmax(predictions[80]))\n",
    "\n",
    "print(predictions[122], np.argmax(predictions[122]))\n",
    "\n",
    "print(predictions[200], np.argmax(predictions[200]))\n",
    "\n",
    "print(predictions[250], np.argmax(predictions[250]))\n",
    "\n",
    "print(predictions[300], np.argmax(predictions[300]))\n",
    "\n",
    "print(predictions[500], np.argmax(predictions[500]))\n",
    "\n",
    "print(predictions[503], np.argmax(predictions[503]))\n",
    "\n",
    "print(predictions[602], np.argmax(predictions[602]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels = []\n",
    "\n",
    "for i in range(1684):\n",
    "    prediction_labels.append(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(test_label, predicted_label):\n",
    "    cm = np.zeros(shape=(4,4))\n",
    "    \n",
    "    for i in range(1684):\n",
    "        cm[int(test_label[i]), int(predicted_label[i])] += 1\n",
    "        \n",
    "    cm[0,:] = cm[0,:]/sum(cm[0,:])\n",
    "    cm[1,:] = cm[1,:]/sum(cm[1,:])\n",
    "    cm[2,:] = cm[2,:]/sum(cm[2,:])\n",
    "    cm[3,:] = cm[3,:]/sum(cm[3,:])\n",
    "    \n",
    "    return cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88198758 0.04347826 0.         0.07453416]\n",
      " [0.03719008 0.94628099 0.         0.01652893]\n",
      " [0.02457002 0.10565111 0.83292383 0.03685504]\n",
      " [0.00457666 0.01029748 0.00457666 0.9805492 ]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_label_converted, prediction_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from keras model to tflite model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def representative_dataset_gen():\n",
    "    for i in range(100):\n",
    "        # creating fake images\n",
    "        image = tf.random.normal([1] + list(image_shape))\n",
    "        yield [image]\n",
    "\n",
    "# actual conversion\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file('keras_model.h5')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = tf.lite.RepresentativeDataset(representative_dataset_gen)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] # For EdgeTPU, no float ops allowed\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "# save model\n",
    "tflite_model = converter.convert()\n",
    "open('model.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def representative_dataset_gen():\n",
    "  for _ in range(num_calibration_steps):\n",
    "    # Get sample input data as a numpy array in a method of your choosing.\n",
    "    yield [input]\n",
    "\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "# tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_shape = (64,64,3)\n",
    "list(image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image = tf.random.normal([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image = tf.random.normal([1]+list(image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = np.float32(test_all)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = test_all[0]\n",
    "\n",
    "y = np.expand_dims(x, axis=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for j in range(100):\n",
    "    print(6*j, j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_spec = np.float32(test_converted)\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for i in range(100):\n",
    "        data = test_all_spec[16*i]\n",
    "        data_dim = np.expand_dims(data, axis=0)\n",
    "        yield [data_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\tensorflow_core\\lite\\python\\util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From C:\\Users\\eeeds\\Anaconda3\\envs\\tf115\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 137 variables.\n",
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# convert a tf.keras model to tflite model\n",
    "converter = tensorflow.lite.TFLiteConverter.from_keras_model_file(\"trained_mobilenet_2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.optimizations = [tensorflow.lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.representative_dataset = tensorflow.lite.RepresentativeDataset(representative_dataset_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.target_spec.supported_ops = [tensorflow.lite.OpsSet.TFLITE_BUILTINS_INT8] # For EdgeTPU, no float ops allowed\n",
    "converter.inference_input_type = tensorflow.uint8\n",
    "converter.inference_output_type = tensorflow.uint8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_mobilenet_2 = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3511296"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('tflite_mobilenet_2.tflite', 'wb').write(tflite_mobilenet_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tensorflow.lite.Interpreter(model_path=\"tflite_mobilenet_2.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'input_2',\n",
       "  'index': 102,\n",
       "  'shape': array([  1, 224, 224,   3]),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.5391271114349365, 113)}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'activation_1/Softmax',\n",
       "  'index': 103,\n",
       "  'shape': array([1, 4]),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.00390625, 0)}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_shape = input_details[0]['shape'] # array([  1, 224, 224,   3])\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)\n",
    "x = np.random.random_sample(input_shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_shape = (1,2,2,3)\n",
    "x = np.random.random_sample(input_shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(test_all[300], test_label[300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = np.expand_dims(test_all[300], axis=0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on random input data.\n",
    "\n",
    "# input_shape = input_details[0]['shape']\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('ground truth:', test_label[300], 'pred:', np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "[[197  25  16  18]]\n",
      "ground truth: [0] pred: 0\n"
     ]
    }
   ],
   "source": [
    "x = np.expand_dims(test_converted[100], axis=0)\n",
    "print(x.shape)\n",
    "\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print('ground truth:', test_label_converted[100], 'pred:', np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "[[ 18 206   7  24]]\n",
      "ground truth: [1] pred: 1\n"
     ]
    }
   ],
   "source": [
    "x = np.expand_dims(test_converted[200], axis=0)\n",
    "print(x.shape)\n",
    "\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print('ground truth:', test_label_converted[200], 'pred:', np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "[[  0   3 247   6]]\n",
      "ground truth: [2] pred: 2\n"
     ]
    }
   ],
   "source": [
    "x = np.expand_dims(test_converted[600], axis=0)\n",
    "print(x.shape)\n",
    "\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print('ground truth:', test_label_converted[600], 'pred:', np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "[[  1  54   6 195]]\n",
      "ground truth: [3] pred: 3\n"
     ]
    }
   ],
   "source": [
    "x = np.expand_dims(test_converted[1000], axis=0)\n",
    "print(x.shape)\n",
    "\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print('ground truth:', test_label_converted[1000], 'pred:', np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "[[  5   4   4 243]]\n",
      "ground truth: [3] pred: 3\n"
     ]
    }
   ],
   "source": [
    "x = np.expand_dims(test_converted[1200], axis=0)\n",
    "print(x.shape)\n",
    "\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print('ground truth:', test_label_converted[1200], 'pred:', np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "[[ 31  18  22 186]]\n",
      "ground truth: [3] pred: 3\n"
     ]
    }
   ],
   "source": [
    "x = np.expand_dims(test_converted[1500], axis=0)\n",
    "print(x.shape)\n",
    "\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print('ground truth:', test_label_converted[1500], 'pred:', np.argmax(output_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n"
     ]
    }
   ],
   "source": [
    "predictions_tflite = []\n",
    "\n",
    "for i in range(1684):\n",
    "    print(i)\n",
    "    x = np.expand_dims(test_converted[i], axis=0)\n",
    "    \n",
    "    input_data = np.array(x, dtype=np.uint8)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    splits_dict = {}\n",
    "    splits_dict['predicted'] = np.argmax(output_data)\n",
    "    splits_dict['ground truth'] = test_label_converted[i]\n",
    "    \n",
    "    predictions_tflite.append(splits_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted': 3, 'ground truth': array([0])},\n",
       " {'predicted': 0, 'ground truth': array([0])}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tflite[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy.save(file, arr, allow_pickle=True, fix_imports=True)[source]\n",
    "np.save('predictions_tflite.npy', predictions_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tflite_loaded = np.load('predictions_tflite.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 0, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])},\n",
       "       {'predicted': 0, 'ground truth': array([1])},\n",
       "       {'predicted': 1, 'ground truth': array([1])}], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_tflite_loaded[300:320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predictions_tflite_all):\n",
    "    cm = np.zeros(shape=(4,4))\n",
    "    \n",
    "    for i in range(1684):\n",
    "        cm[int(predictions_tflite_all[i]['ground truth']), int(predictions_tflite_all[i]['predicted'])] += 1\n",
    "        \n",
    "    cm[0,:] = cm[0,:]/sum(cm[0,:])\n",
    "    cm[1,:] = cm[1,:]/sum(cm[1,:])\n",
    "    cm[2,:] = cm[2,:]/sum(cm[2,:])\n",
    "    cm[3,:] = cm[3,:]/sum(cm[3,:])\n",
    "    \n",
    "    return cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32298137 0.40993789 0.01863354 0.2484472 ]\n",
      " [0.04545455 0.78512397 0.00826446 0.16115702]\n",
      " [0.00737101 0.1031941  0.60933661 0.28009828]\n",
      " [0.         0.00686499 0.00457666 0.98855835]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(predictions_tflite_loaded)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_all.take(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather results for randomly sampled test images\n",
    "predictions = []\n",
    "\n",
    "test_labels, test_data = [], []\n",
    "for data, label in tqdm(test_all.take(10), dtype=np.uint8):\n",
    "    interpreter.set_tensor(input_details[0]['index'], data)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_details[0]['index']))\n",
    "    \n",
    "    test_labels,append(label.numpy()[0])\n",
    "    test_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MobileNet model\n",
    "#vgg_model = keras.applications.vgg16.VGG16(weights='imagenet')\n",
    "mobile_model = keras.applications.mobilenet.MobileNet(weights='imagenet')\n",
    "\n",
    "# Created model is of type Model\n",
    "type(mobile_model)\n",
    "#>> keras.engine.training.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert it to Sequential\n",
    "#model = Sequential() \n",
    "seq_model = Sequential()\n",
    "for layer in mobile_model.layers:\n",
    "   seq_model.add(layer)\n",
    "\n",
    "# Now, check the model type, its Sequential! \n",
    "type(seq_model)\n",
    "#>> keras.models.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the model details\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, that its sequential, we can perform usual operations.\n",
    "seq_model.layers.pop()\n",
    "\n",
    "# Freeze the layers \n",
    "for layer in seq_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add 'softmax' instead of earlier 'prediction' layer.\n",
    "seq_model.add(Dense(4, activation ='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the trainable status of the individual layers\n",
    "for layer in seq_model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the summary, and yes new layer has been added. \n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "training = seq_model.fit(train_all, train_label, epochs=20, validation_data= (test_all, test_label), verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(training.history['acc'])\n",
    "plt.plot(training.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_loss, test_acc = seq_model.evaluate(test_all, test_label)\n",
    "\n",
    "print(\"Tested Acc:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = seq_model.predict(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(train_label[1228]) # 0 to 268, 269 to 619, 620 to 1227, 1228 to 2405\n",
    "print(train_label.shape) # 2406\n",
    "\n",
    "print(test_label[308]) # 0 to 67, 68 to 155, 156 to 307, 308 to 602\n",
    "print(test_label.shape) # 603"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(predictions[0], np.argmax(predictions[0]))\n",
    "\n",
    "print(predictions[44], np.argmax(predictions[44]))\n",
    "\n",
    "print(predictions[80], np.argmax(predictions[80]))\n",
    "\n",
    "print(predictions[122], np.argmax(predictions[122]))\n",
    "\n",
    "print(predictions[200], np.argmax(predictions[200]))\n",
    "\n",
    "print(predictions[250], np.argmax(predictions[250]))\n",
    "\n",
    "print(predictions[300], np.argmax(predictions[300]))\n",
    "\n",
    "print(predictions[500], np.argmax(predictions[500]))\n",
    "\n",
    "print(predictions[503], np.argmax(predictions[503]))\n",
    "\n",
    "print(predictions[602], np.argmax(predictions[602]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save(\"trained_model.h5\")\n",
    "\n",
    "model = keras.models.loead_model('trained_model.h5')\n",
    "\n",
    "predictions = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq_model.save(\"trained_model_mobile.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded_model = keras.models.load_model('trained_model_mobile.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = loaded_model.predict(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(predictions[0], np.argmax(predictions[0]))\n",
    "\n",
    "print(predictions[44], np.argmax(predictions[44]))\n",
    "\n",
    "print(predictions[80], np.argmax(predictions[80]))\n",
    "\n",
    "print(predictions[122], np.argmax(predictions[122]))\n",
    "\n",
    "print(predictions[200], np.argmax(predictions[200]))\n",
    "\n",
    "print(predictions[250], np.argmax(predictions[250]))\n",
    "\n",
    "print(predictions[300], np.argmax(predictions[300]))\n",
    "\n",
    "print(predictions[500], np.argmax(predictions[500]))\n",
    "\n",
    "print(predictions[503], np.argmax(predictions[503]))\n",
    "\n",
    "print(predictions[602], np.argmax(predictions[602]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert a tf.keras model to tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(seq_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tflite_model_mobile = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create VGG model\n",
    "vgg_model = keras.applications.vgg16.VGG16(weights='imagenet')\n",
    "\n",
    "\n",
    "# Created model is of type Model\n",
    "type(vgg_model)\n",
    ">> keras.engine.training.Model\n",
    "\n",
    "\n",
    "# Convert it to Sequential\n",
    "model = Sequential()\n",
    "for layer in vgg_model.layers:\n",
    "   model.add(layer)\n",
    "\n",
    "\n",
    "# Now, check the model type, its Sequential! \n",
    "type(model)\n",
    ">> keras.models.Sequential\n",
    "\n",
    "\n",
    "# Verify the model details\n",
    "model.summary()\n",
    ">> \n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_15 (InputLayer)        (None, 224, 224, 3)       0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 25088)             0         \n",
    "_________________________________________________________________\n",
    "fc1 (Dense)                  (None, 4096)              102764544 \n",
    "_________________________________________________________________\n",
    "fc2 (Dense)                  (None, 4096)              16781312  \n",
    "_________________________________________________________________\n",
    "predictions (Dense)          (None, 1000)              4097000   \n",
    "=================================================================\n",
    "Total params: 138,357,544\n",
    "Trainable params: 138,357,544\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "\n",
    "# Now, that its sequential, we can perform usual operations.\n",
    "model.layers.pop()\n",
    "\n",
    "\n",
    "# Freeze the layers \n",
    "for layer in model.layers:\n",
    "layer.trainable = False\n",
    "\n",
    "\n",
    "# Add 'softmax' instead of earlier 'prediction' layer.\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# Check the summary, and yes new layer has been added. \n",
    "model.summary()\n",
    "\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_15 (InputLayer)        (None, 224, 224, 3)       0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 25088)             0         \n",
    "_________________________________________________________________\n",
    "fc1 (Dense)                  (None, 4096)              102764544 \n",
    "_________________________________________________________________\n",
    "fc2 (Dense)                  (None, 4096)              16781312  \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 2)                 2002      \n",
    "=================================================================\n",
    "Total params: 134,262,546\n",
    "Trainable params: 2,002\n",
    "Non-trainable params: 134,260,544\n",
    "_________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
